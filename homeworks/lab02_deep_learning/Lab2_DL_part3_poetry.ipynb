{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntvTeY0TYzD9"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMfyMrTyYzD-"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kd7q1PV9YzD-"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchsummary\n",
        "import torch.nn.functional as F\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import time\n",
        "from random import sample\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "_9JQdx7iG2dX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EJDiLj8YzD_"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVkDDjqSYzD_"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "idlqQz3dYzD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994abdd5-2aee-42c5-9171-b9f4e2209e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-13 09:53:15--  https://raw.githubusercontent.com/girafe-ai/ml-course/21f_basic/homeworks_basic/lab02_deep_learning/sonnets.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119748 (117K) [text/plain]\n",
            "Saving to: ‘sonnets.txt’\n",
            "\n",
            "sonnets.txt         100%[===================>] 116.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-12-13 09:53:15 (5.65 MB/s) - ‘sonnets.txt’ saved [119748/119748]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# if not os.path.exists('sonnets.txt'):\n",
        "#     !wget https://raw.githubusercontent.com/girafe-ai/ml-course/21f_basic/homeworks_basic/lab02_deep_learning/sonnets.txt\n",
        "\n",
        "# with open('sonnets.txt', 'r') as iofile:\n",
        "#     text = iofile.readlines()\n",
        "    \n",
        "# TEXT_START = 45\n",
        "# TEXT_END = -368\n",
        "# text = text[TEXT_START : TEXT_END]\n",
        "# assert len(text) == 2616"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqXoBlmHYzEA"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t8oJesjyYzEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33660da5-3e50-4d42-8e46-f78025083276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK!\n"
          ]
        }
      ],
      "source": [
        "# # Join all the strings into one and lowercase it\n",
        "# # Put result into variable text.\n",
        "\n",
        "# # Your great code here\n",
        "# text = ''.join(text).lower()\n",
        "\n",
        "\n",
        "# assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "# assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "# print('OK!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaJ6iMEUYzEA"
      },
      "source": [
        "### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "U4lH0Vf2YzEA",
        "outputId": "867a5c6d-6c37-436e-85ab-3f2bdc77471a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-13 16:31:29--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt.1’\n",
            "\n",
            "\ronegin.txt.1          0%[                    ]       0  --.-KB/s               \ronegin.txt.1        100%[===================>] 256.37K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-12-13 16:31:29 (8.00 MB/s) - ‘onegin.txt.1’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "    \n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "text = [x.replace('\\t\\t', '') for x in text]\n",
        "text = ''.join(text).lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYXgZi2xYzEB"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNsqv8DYzEB"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS = '<' #start of sequence token\n",
        "EOF = '>' #end of sequence token\n",
        "SOS in set(text) or EOF in set(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbWl2P2YTFn4",
        "outputId": "998b3167-073e-4d26-c009-9716bf66c263"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "y75qko8QYzEB"
      },
      "outputs": [],
      "source": [
        "tokens = sorted(set(text))\n",
        "tokens.append(SOS)\n",
        "tokens.append(EOF)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUDe5svITBz9",
        "outputId": "bd106239-0ab3-43ee-84cb-b35ab7d25e68"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '5',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " '^',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '«',\n",
              " '»',\n",
              " 'а',\n",
              " 'б',\n",
              " 'в',\n",
              " 'г',\n",
              " 'д',\n",
              " 'е',\n",
              " 'ж',\n",
              " 'з',\n",
              " 'и',\n",
              " 'й',\n",
              " 'к',\n",
              " 'л',\n",
              " 'м',\n",
              " 'н',\n",
              " 'о',\n",
              " 'п',\n",
              " 'р',\n",
              " 'с',\n",
              " 'т',\n",
              " 'у',\n",
              " 'ф',\n",
              " 'х',\n",
              " 'ц',\n",
              " 'ч',\n",
              " 'ш',\n",
              " 'щ',\n",
              " 'ъ',\n",
              " 'ы',\n",
              " 'ь',\n",
              " 'э',\n",
              " 'ю',\n",
              " 'я',\n",
              " 'ё',\n",
              " '–',\n",
              " '—',\n",
              " '’',\n",
              " '…',\n",
              " '€',\n",
              " '<',\n",
              " '>']"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BNsohKJYzEC"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "collapsed": true,
        "id": "a3yKpCauYzEC"
      },
      "outputs": [],
      "source": [
        "# dict <index>:<char>\n",
        "# Your great code here\n",
        "token_to_idx = {u:i for i, u in enumerate(tokens)}\n",
        "\n",
        "# dict <char>:<index>\n",
        "# Your great code here\n",
        "idx_to_token = {i:u for i, u in enumerate(tokens)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwq2dzTqYzEC"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uovx-kyRYzEC"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxKGmW_DYzEC"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(tokens)\n",
        "RNN_SIZE = 256 #The number of features in the hidden state h\n",
        "EMBEDDING_SIZE = 64 # The number of features in the input x/How mane features reperesent token\n",
        "SEQUENCE_SIZE = 100 # Length of each sequence/Number of hidden layers\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100"
      ],
      "metadata": {
        "id": "oAHxcMihH4lx"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_matrix(text, token_to_idx=token_to_idx, seq_size=SEQUENCE_SIZE, batch_size=BATCH_SIZE):\n",
        "    \"\"\"\n",
        "    Casts a text into rnn-digestable matrix of shape (batch_size * num_batches) x (seq_size + 2).\n",
        "    \"\"\"\n",
        "    char_ints = [token_to_idx[char] for char in text]\n",
        "    num_batches = int(len(char_ints) / (batch_size * seq_size)) # if we don't have enough tokens for last batch, then it's delested\n",
        "    matrix = np.zeros((num_batches * batch_size, seq_size + 2), dtype='int32')\n",
        "\n",
        "    for i in range(batch_size * num_batches):\n",
        "        matrix[i] = [token_to_idx[SOS]] + char_ints[i * seq_size:(i + 1) * seq_size] + [token_to_idx[EOF]]\n",
        "\n",
        "    return matrix"
      ],
      "metadata": {
        "id": "-eRcUbdKUXPb"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(to_matrix(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-ggiiOqUknY",
        "outputId": "7a2b9822-9a4f-4059-d4d8-669e291ff5cb"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[83  0 26 ... 64 57 84]\n",
            " [83 45 63 ... 59 63 84]\n",
            " [83 66 59 ... 60 59 84]\n",
            " ...\n",
            " [83 53  1 ... 53 57 84]\n",
            " [83  0 49 ...  1 56 84]\n",
            " [83 53 14 ... 55 45 84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(text) - len(to_matrix(text, token_to_idx)) * len(to_matrix(text, token_to_idx)[0]) < BATCH_SIZE * SEQUENCE_SIZE\n",
        "assert len(to_matrix(text, token_to_idx)) % BATCH_SIZE == 0"
      ],
      "metadata": {
        "id": "uyhwO-CQgOZa"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "collapsed": true,
        "id": "M6PzUnkbYzED"
      },
      "outputs": [],
      "source": [
        "class VanilaRNN(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=EMBEDDING_SIZE, rnn_num_units=RNN_SIZE):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        h_seq, h_state = self.rnn(self.emb(x), h_prev)\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        return next_logits, h_state\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(1, batch_size, self.num_units, requires_grad=True)\n",
        "    \n",
        "model = VanilaRNN().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, text, loss_func=loss_func, opt=opt, is_lstm=False):\n",
        "    batches = to_matrix(text)\n",
        "    train_loss = []\n",
        "    for epoch in range(EPOCHS):\n",
        "        ep_train_loss = []\n",
        "        permutation = torch.randperm(len(batches))\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "        if is_lstm:\n",
        "            state_h, state_c = model.initial_state(BATCH_SIZE)\n",
        "            state_h = state_h.to(device)\n",
        "            state_c = state_c.to(device)\n",
        "        else:\n",
        "            hid_state = model.initial_state(BATCH_SIZE).to(device)\n",
        "        for i in range(0, len(batches), BATCH_SIZE):\n",
        "            batch_ind = permutation[i:i + BATCH_SIZE]\n",
        "            batch = torch.tensor(batches[batch_ind], dtype=torch.int64).to(device)\n",
        "            \n",
        "            if is_lstm:\n",
        "                logits_seq, (state_h, state_c) = model(batch, (state_h, state_c))\n",
        "                state_h = state_h.detach()\n",
        "                state_c = state_c.detach()\n",
        "            else:\n",
        "                logits_seq, hid_state = model(batch, hid_state)\n",
        "                hid_state = hid_state.detach()\n",
        "            # compute loss\n",
        "            predictions_logits = logits_seq[:, :-1]\n",
        "            actual_next_tokens = batch[:, 1:]\n",
        "\n",
        "            loss = loss_func(\n",
        "                predictions_logits.reshape((-1, num_tokens)),\n",
        "                actual_next_tokens.reshape(-1)\n",
        "            )\n",
        "            loss.backward()\n",
        "\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "            ep_train_loss.append(loss.item())\n",
        "\n",
        "        train_loss.append(np.mean(ep_train_loss))\n",
        "        print(f'Epoch {epoch + 1} of {EPOCHS} took {time.time() - start_time:.3f}s')\n",
        "        print(f\"\\t  training loss: {train_loss[-1]:.6f}\")\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "YgNHZqeXmBmc"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = train_model(model, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BouaLkX3vii",
        "outputId": "ca643cdd-251d-4b1e-cc23-0b9639170495"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 100 took 2.591s\n",
            "\t  training loss: 3.509656\n",
            "Epoch 2 of 100 took 2.611s\n",
            "\t  training loss: 2.956570\n",
            "Epoch 3 of 100 took 2.534s\n",
            "\t  training loss: 2.741417\n",
            "Epoch 4 of 100 took 2.544s\n",
            "\t  training loss: 2.618251\n",
            "Epoch 5 of 100 took 2.534s\n",
            "\t  training loss: 2.543511\n",
            "Epoch 6 of 100 took 2.578s\n",
            "\t  training loss: 2.488120\n",
            "Epoch 7 of 100 took 2.523s\n",
            "\t  training loss: 2.442240\n",
            "Epoch 8 of 100 took 2.531s\n",
            "\t  training loss: 2.402827\n",
            "Epoch 9 of 100 took 2.566s\n",
            "\t  training loss: 2.367663\n",
            "Epoch 10 of 100 took 2.612s\n",
            "\t  training loss: 2.333281\n",
            "Epoch 11 of 100 took 2.520s\n",
            "\t  training loss: 2.302429\n",
            "Epoch 12 of 100 took 2.526s\n",
            "\t  training loss: 2.275947\n",
            "Epoch 13 of 100 took 2.520s\n",
            "\t  training loss: 2.252339\n",
            "Epoch 14 of 100 took 2.551s\n",
            "\t  training loss: 2.226297\n",
            "Epoch 15 of 100 took 2.526s\n",
            "\t  training loss: 2.203893\n",
            "Epoch 16 of 100 took 2.525s\n",
            "\t  training loss: 2.184013\n",
            "Epoch 17 of 100 took 2.523s\n",
            "\t  training loss: 2.164145\n",
            "Epoch 18 of 100 took 2.579s\n",
            "\t  training loss: 2.144219\n",
            "Epoch 19 of 100 took 2.536s\n",
            "\t  training loss: 2.125225\n",
            "Epoch 20 of 100 took 2.540s\n",
            "\t  training loss: 2.110536\n",
            "Epoch 21 of 100 took 2.568s\n",
            "\t  training loss: 2.094709\n",
            "Epoch 22 of 100 took 2.606s\n",
            "\t  training loss: 2.079652\n",
            "Epoch 23 of 100 took 2.530s\n",
            "\t  training loss: 2.063493\n",
            "Epoch 24 of 100 took 2.523s\n",
            "\t  training loss: 2.054229\n",
            "Epoch 25 of 100 took 2.539s\n",
            "\t  training loss: 2.040184\n",
            "Epoch 26 of 100 took 2.557s\n",
            "\t  training loss: 2.028883\n",
            "Epoch 27 of 100 took 2.513s\n",
            "\t  training loss: 2.018262\n",
            "Epoch 28 of 100 took 2.523s\n",
            "\t  training loss: 2.001895\n",
            "Epoch 29 of 100 took 2.533s\n",
            "\t  training loss: 1.990824\n",
            "Epoch 30 of 100 took 2.566s\n",
            "\t  training loss: 1.979109\n",
            "Epoch 31 of 100 took 2.523s\n",
            "\t  training loss: 1.968952\n",
            "Epoch 32 of 100 took 2.525s\n",
            "\t  training loss: 1.959101\n",
            "Epoch 33 of 100 took 2.565s\n",
            "\t  training loss: 1.950105\n",
            "Epoch 34 of 100 took 2.527s\n",
            "\t  training loss: 1.939200\n",
            "Epoch 35 of 100 took 2.550s\n",
            "\t  training loss: 1.931471\n",
            "Epoch 36 of 100 took 2.544s\n",
            "\t  training loss: 1.923429\n",
            "Epoch 37 of 100 took 2.538s\n",
            "\t  training loss: 1.917432\n",
            "Epoch 38 of 100 took 2.611s\n",
            "\t  training loss: 1.903976\n",
            "Epoch 39 of 100 took 2.557s\n",
            "\t  training loss: 1.892967\n",
            "Epoch 40 of 100 took 2.561s\n",
            "\t  training loss: 1.888780\n",
            "Epoch 41 of 100 took 2.553s\n",
            "\t  training loss: 1.879799\n",
            "Epoch 42 of 100 took 2.555s\n",
            "\t  training loss: 1.869785\n",
            "Epoch 43 of 100 took 2.553s\n",
            "\t  training loss: 1.861490\n",
            "Epoch 44 of 100 took 2.544s\n",
            "\t  training loss: 1.855511\n",
            "Epoch 45 of 100 took 2.519s\n",
            "\t  training loss: 1.846127\n",
            "Epoch 46 of 100 took 2.525s\n",
            "\t  training loss: 1.838956\n",
            "Epoch 47 of 100 took 2.529s\n",
            "\t  training loss: 1.834418\n",
            "Epoch 48 of 100 took 2.524s\n",
            "\t  training loss: 1.826257\n",
            "Epoch 49 of 100 took 2.519s\n",
            "\t  training loss: 1.817586\n",
            "Epoch 50 of 100 took 2.553s\n",
            "\t  training loss: 1.815399\n",
            "Epoch 51 of 100 took 2.579s\n",
            "\t  training loss: 1.808332\n",
            "Epoch 52 of 100 took 2.531s\n",
            "\t  training loss: 1.796597\n",
            "Epoch 53 of 100 took 2.537s\n",
            "\t  training loss: 1.789794\n",
            "Epoch 54 of 100 took 2.533s\n",
            "\t  training loss: 1.788532\n",
            "Epoch 55 of 100 took 2.534s\n",
            "\t  training loss: 1.777303\n",
            "Epoch 56 of 100 took 2.514s\n",
            "\t  training loss: 1.772182\n",
            "Epoch 57 of 100 took 2.528s\n",
            "\t  training loss: 1.764872\n",
            "Epoch 58 of 100 took 2.561s\n",
            "\t  training loss: 1.757965\n",
            "Epoch 59 of 100 took 2.526s\n",
            "\t  training loss: 1.753026\n",
            "Epoch 60 of 100 took 2.561s\n",
            "\t  training loss: 1.748170\n",
            "Epoch 61 of 100 took 2.537s\n",
            "\t  training loss: 1.741715\n",
            "Epoch 62 of 100 took 2.520s\n",
            "\t  training loss: 1.736662\n",
            "Epoch 63 of 100 took 2.651s\n",
            "\t  training loss: 1.730005\n",
            "Epoch 64 of 100 took 2.575s\n",
            "\t  training loss: 1.725137\n",
            "Epoch 65 of 100 took 2.545s\n",
            "\t  training loss: 1.717521\n",
            "Epoch 66 of 100 took 2.566s\n",
            "\t  training loss: 1.712223\n",
            "Epoch 67 of 100 took 2.594s\n",
            "\t  training loss: 1.712111\n",
            "Epoch 68 of 100 took 2.539s\n",
            "\t  training loss: 1.702481\n",
            "Epoch 69 of 100 took 2.558s\n",
            "\t  training loss: 1.696833\n",
            "Epoch 70 of 100 took 2.561s\n",
            "\t  training loss: 1.689645\n",
            "Epoch 71 of 100 took 2.565s\n",
            "\t  training loss: 1.686198\n",
            "Epoch 72 of 100 took 2.662s\n",
            "\t  training loss: 1.679588\n",
            "Epoch 73 of 100 took 2.599s\n",
            "\t  training loss: 1.672471\n",
            "Epoch 74 of 100 took 2.598s\n",
            "\t  training loss: 1.668009\n",
            "Epoch 75 of 100 took 2.589s\n",
            "\t  training loss: 1.666457\n",
            "Epoch 76 of 100 took 2.538s\n",
            "\t  training loss: 1.659505\n",
            "Epoch 77 of 100 took 2.533s\n",
            "\t  training loss: 1.658059\n",
            "Epoch 78 of 100 took 2.536s\n",
            "\t  training loss: 1.647784\n",
            "Epoch 79 of 100 took 2.551s\n",
            "\t  training loss: 1.641244\n",
            "Epoch 80 of 100 took 2.552s\n",
            "\t  training loss: 1.637601\n",
            "Epoch 81 of 100 took 2.516s\n",
            "\t  training loss: 1.632342\n",
            "Epoch 82 of 100 took 2.532s\n",
            "\t  training loss: 1.627514\n",
            "Epoch 83 of 100 took 2.557s\n",
            "\t  training loss: 1.622535\n",
            "Epoch 84 of 100 took 2.536s\n",
            "\t  training loss: 1.622307\n",
            "Epoch 85 of 100 took 2.524s\n",
            "\t  training loss: 1.615938\n",
            "Epoch 86 of 100 took 2.499s\n",
            "\t  training loss: 1.607550\n",
            "Epoch 87 of 100 took 2.538s\n",
            "\t  training loss: 1.605798\n",
            "Epoch 88 of 100 took 2.522s\n",
            "\t  training loss: 1.599663\n",
            "Epoch 89 of 100 took 2.568s\n",
            "\t  training loss: 1.595644\n",
            "Epoch 90 of 100 took 2.528s\n",
            "\t  training loss: 1.593223\n",
            "Epoch 91 of 100 took 2.579s\n",
            "\t  training loss: 1.587339\n",
            "Epoch 92 of 100 took 2.554s\n",
            "\t  training loss: 1.580823\n",
            "Epoch 93 of 100 took 2.524s\n",
            "\t  training loss: 1.575315\n",
            "Epoch 94 of 100 took 2.550s\n",
            "\t  training loss: 1.569515\n",
            "Epoch 95 of 100 took 2.556s\n",
            "\t  training loss: 1.567890\n",
            "Epoch 96 of 100 took 2.515s\n",
            "\t  training loss: 1.562968\n",
            "Epoch 97 of 100 took 2.542s\n",
            "\t  training loss: 1.557821\n",
            "Epoch 98 of 100 took 2.505s\n",
            "\t  training loss: 1.551522\n",
            "Epoch 99 of 100 took 2.522s\n",
            "\t  training loss: 1.553314\n",
            "Epoch 100 of 100 took 2.531s\n",
            "\t  training loss: 1.550161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVLtuUGKYzED"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "collapsed": true,
        "id": "TxuoRzhmYzED"
      },
      "outputs": [],
      "source": [
        "def plot_loss(loss):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"#epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.plot(loss)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "sFnA6uiX9__B",
        "outputId": "67965044-4a47-46a9-8dcd-450967e112ba"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "_fDp52GZYzED"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, seed_phrase=SOS, temperature=1.0, token_to_idx=token_to_idx, idx_to_token=idx_to_token, max_length=100, is_lstm=False):\n",
        "    '''\n",
        "    ### Disclaimer: this is an example function for text generation.\n",
        "    ### You can either adapt it in your code or create your own function\n",
        "    \n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
        "        smaller temperature converges to the single most likely output.\n",
        "        \n",
        "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
        "    of the next symbol.\n",
        "    '''\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "        if is_lstm:\n",
        "            state_h, state_c = model.initial_state(1)\n",
        "            state_h = state_h.to(device)\n",
        "            state_c = state_c.to(device)\n",
        "        else:\n",
        "            hid_state = model.initial_state(1).to(device)\n",
        "\n",
        "        #feed the seed phrase, if any\n",
        "        for i in range(len(seed_phrase)):\n",
        "            ix = torch.tensor([[x_sequence[i]]]).to(device)\n",
        "            if is_lstm:\n",
        "                logits_next, (state_h, state_c) = model(ix, (state_h, state_c))\n",
        "            else:\n",
        "                logits_next, hid_state = model(ix, hid_state)\n",
        "        #start generating\n",
        "        for _ in range(max_length - len(seed_phrase)):\n",
        "            ix = torch.tensor([[x_sequence[i]]]).to(device)\n",
        "            ix = torch.tensor([[x_sequence[-1]]]).to(device)\n",
        "            if is_lstm:\n",
        "                logits_next, (state_h, state_c) = model(ix, (state_h, state_c))\n",
        "            else:\n",
        "                logits_next, hid_state = model(ix, hid_state)\n",
        "            # Be really careful here with the model output\n",
        "            p_next = F.softmax(logits_next / temperature, dim=-1).data.numpy()[0][0]\n",
        "            \n",
        "            # sample next token and push it back into x_sequence\n",
        "            next_ix = np.random.choice(len(tokens), p=p_next)\n",
        "            if next_ix == token_to_idx[EOF]:\n",
        "                break\n",
        "            x_sequence.append(next_ix)\n",
        "\n",
        "        \n",
        "    return ''.join([idx_to_token[ix] for ix in x_sequence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "Fv_q7ghyYzEE",
        "outputId": "c5a73104-502c-4619-8d68-28e86790868a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "любимая екатерина постойтет\n",
            "на простительно не умела\n",
            "пора долго в нем старый своей.\n",
            "\n",
            "\n",
            "\n",
            "xxxiii\n",
            "\n",
            "он был по небо весель\n"
          ]
        }
      ],
      "source": [
        "# An example of generated text.\n",
        "print(generate_text(model, seed_phrase='любимая екатерина постойте', max_length=500, temperature=0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIBftyD7YzEE"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=EMBEDDING_SIZE, rnn_num_units=RNN_SIZE):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.LSTM(emb_size, rnn_num_units, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        h_seq, h_state = self.rnn(self.emb(x), h_prev)\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        return next_logits, h_state\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(1, batch_size, self.num_units, requires_grad=True), torch.zeros(1, batch_size, self.num_units, requires_grad=True)\n",
        "    \n",
        "model = LSTM().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Q0vVuOcuWl3N"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = train_model(model, text, is_lstm=True, opt=opt, loss_func=loss_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZaMvNWYYJy6",
        "outputId": "2bf5b75c-d633-42b2-dda3-3aafdc8b4ee8"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 100 took 20.504s\n",
            "\t  training loss: 3.738509\n",
            "Epoch 2 of 100 took 12.399s\n",
            "\t  training loss: 3.140505\n",
            "Epoch 3 of 100 took 9.701s\n",
            "\t  training loss: 2.911374\n",
            "Epoch 4 of 100 took 8.753s\n",
            "\t  training loss: 2.749551\n",
            "Epoch 5 of 100 took 8.935s\n",
            "\t  training loss: 2.648823\n",
            "Epoch 6 of 100 took 8.833s\n",
            "\t  training loss: 2.577192\n",
            "Epoch 7 of 100 took 8.804s\n",
            "\t  training loss: 2.520009\n",
            "Epoch 8 of 100 took 8.699s\n",
            "\t  training loss: 2.472799\n",
            "Epoch 9 of 100 took 8.781s\n",
            "\t  training loss: 2.429574\n",
            "Epoch 10 of 100 took 8.752s\n",
            "\t  training loss: 2.394029\n",
            "Epoch 11 of 100 took 10.367s\n",
            "\t  training loss: 2.362360\n",
            "Epoch 12 of 100 took 8.843s\n",
            "\t  training loss: 2.335394\n",
            "Epoch 13 of 100 took 9.539s\n",
            "\t  training loss: 2.311590\n",
            "Epoch 14 of 100 took 8.674s\n",
            "\t  training loss: 2.287963\n",
            "Epoch 15 of 100 took 8.654s\n",
            "\t  training loss: 2.268879\n",
            "Epoch 16 of 100 took 8.637s\n",
            "\t  training loss: 2.246716\n",
            "Epoch 17 of 100 took 8.731s\n",
            "\t  training loss: 2.227460\n",
            "Epoch 18 of 100 took 8.801s\n",
            "\t  training loss: 2.209824\n",
            "Epoch 19 of 100 took 8.734s\n",
            "\t  training loss: 2.192718\n",
            "Epoch 20 of 100 took 8.692s\n",
            "\t  training loss: 2.178232\n",
            "Epoch 21 of 100 took 8.672s\n",
            "\t  training loss: 2.162467\n",
            "Epoch 22 of 100 took 8.649s\n",
            "\t  training loss: 2.147343\n",
            "Epoch 23 of 100 took 8.652s\n",
            "\t  training loss: 2.131705\n",
            "Epoch 24 of 100 took 8.761s\n",
            "\t  training loss: 2.117644\n",
            "Epoch 25 of 100 took 8.785s\n",
            "\t  training loss: 2.103176\n",
            "Epoch 26 of 100 took 8.673s\n",
            "\t  training loss: 2.095575\n",
            "Epoch 27 of 100 took 8.686s\n",
            "\t  training loss: 2.077384\n",
            "Epoch 28 of 100 took 8.704s\n",
            "\t  training loss: 2.064781\n",
            "Epoch 29 of 100 took 8.717s\n",
            "\t  training loss: 2.052807\n",
            "Epoch 30 of 100 took 8.663s\n",
            "\t  training loss: 2.040326\n",
            "Epoch 31 of 100 took 8.641s\n",
            "\t  training loss: 2.029376\n",
            "Epoch 32 of 100 took 8.761s\n",
            "\t  training loss: 2.017950\n",
            "Epoch 33 of 100 took 8.649s\n",
            "\t  training loss: 2.007436\n",
            "Epoch 34 of 100 took 8.671s\n",
            "\t  training loss: 1.996688\n",
            "Epoch 35 of 100 took 8.727s\n",
            "\t  training loss: 1.989480\n",
            "Epoch 36 of 100 took 8.644s\n",
            "\t  training loss: 1.975285\n",
            "Epoch 37 of 100 took 9.620s\n",
            "\t  training loss: 1.964343\n",
            "Epoch 38 of 100 took 8.790s\n",
            "\t  training loss: 1.954842\n",
            "Epoch 39 of 100 took 8.851s\n",
            "\t  training loss: 1.946947\n",
            "Epoch 40 of 100 took 8.636s\n",
            "\t  training loss: 1.935880\n",
            "Epoch 41 of 100 took 8.723s\n",
            "\t  training loss: 1.926046\n",
            "Epoch 42 of 100 took 8.684s\n",
            "\t  training loss: 1.916537\n",
            "Epoch 43 of 100 took 8.566s\n",
            "\t  training loss: 1.906333\n",
            "Epoch 44 of 100 took 8.608s\n",
            "\t  training loss: 1.898641\n",
            "Epoch 45 of 100 took 8.575s\n",
            "\t  training loss: 1.889939\n",
            "Epoch 46 of 100 took 8.697s\n",
            "\t  training loss: 1.880025\n",
            "Epoch 47 of 100 took 8.689s\n",
            "\t  training loss: 1.871560\n",
            "Epoch 48 of 100 took 8.672s\n",
            "\t  training loss: 1.862424\n",
            "Epoch 49 of 100 took 8.685s\n",
            "\t  training loss: 1.853968\n",
            "Epoch 50 of 100 took 8.666s\n",
            "\t  training loss: 1.844587\n",
            "Epoch 51 of 100 took 8.626s\n",
            "\t  training loss: 1.835308\n",
            "Epoch 52 of 100 took 8.603s\n",
            "\t  training loss: 1.826405\n",
            "Epoch 53 of 100 took 8.693s\n",
            "\t  training loss: 1.819092\n",
            "Epoch 54 of 100 took 8.611s\n",
            "\t  training loss: 1.810325\n",
            "Epoch 55 of 100 took 8.907s\n",
            "\t  training loss: 1.800949\n",
            "Epoch 56 of 100 took 8.662s\n",
            "\t  training loss: 1.793053\n",
            "Epoch 57 of 100 took 8.678s\n",
            "\t  training loss: 1.785576\n",
            "Epoch 58 of 100 took 8.610s\n",
            "\t  training loss: 1.777059\n",
            "Epoch 59 of 100 took 8.680s\n",
            "\t  training loss: 1.770044\n",
            "Epoch 60 of 100 took 8.724s\n",
            "\t  training loss: 1.761606\n",
            "Epoch 61 of 100 took 8.689s\n",
            "\t  training loss: 1.751919\n",
            "Epoch 62 of 100 took 8.675s\n",
            "\t  training loss: 1.743958\n",
            "Epoch 63 of 100 took 8.656s\n",
            "\t  training loss: 1.735841\n",
            "Epoch 64 of 100 took 8.671s\n",
            "\t  training loss: 1.728360\n",
            "Epoch 65 of 100 took 8.658s\n",
            "\t  training loss: 1.720472\n",
            "Epoch 66 of 100 took 8.641s\n",
            "\t  training loss: 1.712819\n",
            "Epoch 67 of 100 took 8.793s\n",
            "\t  training loss: 1.705109\n",
            "Epoch 68 of 100 took 8.732s\n",
            "\t  training loss: 1.697641\n",
            "Epoch 69 of 100 took 9.596s\n",
            "\t  training loss: 1.689218\n",
            "Epoch 70 of 100 took 8.634s\n",
            "\t  training loss: 1.681962\n",
            "Epoch 71 of 100 took 8.626s\n",
            "\t  training loss: 1.673504\n",
            "Epoch 72 of 100 took 8.655s\n",
            "\t  training loss: 1.667865\n",
            "Epoch 73 of 100 took 8.759s\n",
            "\t  training loss: 1.660215\n",
            "Epoch 74 of 100 took 10.295s\n",
            "\t  training loss: 1.650656\n",
            "Epoch 75 of 100 took 8.689s\n",
            "\t  training loss: 1.643011\n",
            "Epoch 76 of 100 took 8.667s\n",
            "\t  training loss: 1.634996\n",
            "Epoch 77 of 100 took 8.633s\n",
            "\t  training loss: 1.627765\n",
            "Epoch 78 of 100 took 8.587s\n",
            "\t  training loss: 1.619449\n",
            "Epoch 79 of 100 took 8.649s\n",
            "\t  training loss: 1.612150\n",
            "Epoch 80 of 100 took 8.677s\n",
            "\t  training loss: 1.610958\n",
            "Epoch 81 of 100 took 8.717s\n",
            "\t  training loss: 1.607715\n",
            "Epoch 82 of 100 took 8.680s\n",
            "\t  training loss: 1.594301\n",
            "Epoch 83 of 100 took 8.644s\n",
            "\t  training loss: 1.582876\n",
            "Epoch 84 of 100 took 8.750s\n",
            "\t  training loss: 1.574913\n",
            "Epoch 85 of 100 took 8.743s\n",
            "\t  training loss: 1.568719\n",
            "Epoch 86 of 100 took 8.725s\n",
            "\t  training loss: 1.561299\n",
            "Epoch 87 of 100 took 8.784s\n",
            "\t  training loss: 1.551948\n",
            "Epoch 88 of 100 took 8.711s\n",
            "\t  training loss: 1.543828\n",
            "Epoch 89 of 100 took 8.723s\n",
            "\t  training loss: 1.535481\n",
            "Epoch 90 of 100 took 8.645s\n",
            "\t  training loss: 1.528149\n",
            "Epoch 91 of 100 took 8.672s\n",
            "\t  training loss: 1.520546\n",
            "Epoch 92 of 100 took 8.662s\n",
            "\t  training loss: 1.512348\n",
            "Epoch 93 of 100 took 8.770s\n",
            "\t  training loss: 1.505917\n",
            "Epoch 94 of 100 took 8.876s\n",
            "\t  training loss: 1.496541\n",
            "Epoch 95 of 100 took 8.683s\n",
            "\t  training loss: 1.490395\n",
            "Epoch 96 of 100 took 8.674s\n",
            "\t  training loss: 1.483556\n",
            "Epoch 97 of 100 took 8.676s\n",
            "\t  training loss: 1.473931\n",
            "Epoch 98 of 100 took 8.614s\n",
            "\t  training loss: 1.466979\n",
            "Epoch 99 of 100 took 8.620s\n",
            "\t  training loss: 1.460528\n",
            "Epoch 100 of 100 took 8.865s\n",
            "\t  training loss: 1.450659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzIdVPV8YzEE"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "collapsed": true,
        "id": "FWwguQfmYzEE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "24ead91a-e8a8-464c-997c-bace165fce51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcV3nv+99b1TV1dXdVz7PUmmxFsmzZlmc7SMZ2HOJgQrAh4YTAMXGSGwi5kBzCSUIOPOESLkMghwQOiQnDJZjgkAQM8YBsxTbYsiUPmm3NQ8/zXD2u+8eubrWklq2hq3Z39ffzPPXUsHd1vwXrqfZPa6/1mnNOAAAAAICFL+B3AQAAAACAuUHAAwAAAIAcQcADAAAAgBxBwAMAAACAHEHAAwAAAIAcQcADAAAAgBxBwAMAAACAHEHAAwAsemZ2xMxu87sOAAAuFgEPAAAAAHIEAQ8AgFmYWcTMvmhmTenbF80skj5WZmYPm1mPmXWZ2dNmFkgf+6iZNZpZv5m9amZv9veTAAAWkzy/CwAAYJ76M0nXS1ovyUn6D0l/LukvJH1E0glJ5elzr5fkzOxSSR+QdI1zrsnMGiQFs1s2AGAxYwYPAIDZvVvSJ51zbc65dkmfkPRb6WNjkqolLXXOjTnnnnbOOUkTkiKS1phZyDl3xDl30JfqAQCLEgEPAIDZ1Ug6OuP50fRrkvRZSQckPWZmh8zsTyXJOXdA0h9J+l+S2szsQTOrEQAAWULAAwBgdk2Sls54viT9mpxz/c65jzjnlkt6q6QPT621c879s3Pu5vR7naTPZLdsAMBiRsADAMATMrPo1E3SdyX9uZmVm1mZpI9L+v8kyczuMrOVZmaSeuVdmjlpZpea2a3pzVhSkoYlTfrzcQAAixEBDwAAz0/kBbKpW1TSNkk7JO2U9KKkv0qfu0rSTyUNSHpW0t87556Ut/7uryV1SGqRVCHpY9n7CACAxc68NeEAAAAAgIWOGTwAAAAAyBEEPAAAAADIEQQ8AAAAAMgRBDwAAAAAyBEEPAAAAADIEXl+F3C+ysrKXENDg99lnGFwcFDxeNzvMpDjGGfIBsYZMo0xhmxgnCEb/Bpn27dv73DOlc92bMEFvIaGBm3bts3vMs6wZcsWbdy40e8ykOMYZ8gGxhkyjTGGbGCcIRv8GmdmdvRsx7hEEwAAAAByBAEPAAAAAHIEAQ8AAAAAcgQBDwAAAAByBAEPAAAAAHIEAQ8AAAAAcgQBDwAAAAByBAEPAAAAAHIEAQ8AAAAAcgQBbw7sauzVk8fG/C4DAAAAwCJHwJsDP93bqm/uGdXI+ITfpQAAAABYxAh4c6AmGZMktfSmfK4EAAAAwGJGwJsDdemA19g97HMlAAAAABYzAt4cmJrBa+wh4AEAAADwDwFvDlQno5Kkph4u0QQAAADgHwLeHIjkBZWImBp7hvwuBQAAAMAiRsCbI6VRYwYPAAAAgK8IeHOkNGaswQMAAADgKwLeHCmNegHPOed3KQAAAAAWKQLeHCmNBTQ6PqmOgVG/SwEAAACwSBHw5khp1CRJTVymCQAAAMAnBLw5UhrzAh7r8AAAAAD4hYA3R0qj3v+UzOABAAAA8AsBb47EQ1I8HNSJbgIeAAAAAH8Q8OaImakmGWMGDwAAAIBvCHhzqLY4xho8AAAAAL4h4M0hZvAAAAAA+ImAN4dqkzF1D41paHTc71IAAAAALEIEvDlUm4xJYidNAAAAAP4g4M2h2mIv4DX2pHyuBAAAAMBiRMCbQzXpGbxGWiUAAAAA8AEBbw5VFkYUDBiXaAIAAADwRcYCnplFzex5M3vFzHab2SdmOee9ZtZuZi+nb+/PVD3ZkBcMqKooSqsEAAAAAL7Iy+DPHpF0q3NuwMxCkp4xs/90zj132nnfc859IIN1ZFVtkl54AAAAAPyRsRk85xlIPw2lby5Tv2++qElGWYMHAAAAwBcZXYNnZkEze1lSm6THnXNbZznt181sh5k9ZGb1mawnG2qLY2rpS2liMuezLAAAAIB5xpzLfBAxs6Skf5P0Qefcrhmvl0oacM6NmNnvSnqnc+7WWd5/v6T7JamysvLqBx98MOM1n6+BgQEVFBToyWNj+uaeUX3+TTGVxtjDBnNrapwBmcQ4Q6YxxpANjDNkg1/jbNOmTdudcxtmO5aVgCdJZvZxSUPOuc+d5XhQUpdzLvF6P2fDhg1u27ZtmSjxomzZskUbN27Ullfb9N5/ekEP/d4N2tBQ4ndZyDFT4wzIJMYZMo0xhmxgnCEb/BpnZnbWgJfJXTTL0zN3MrOYpNsl7TvtnOoZT98qaW+m6smW2qleeGy0AgAAACDLMrmLZrWkb6Zn5gKS/sU597CZfVLSNufcDyX9oZm9VdK4pC5J781gPVlRQ8ADAAAA4JOMBTzn3A5JV87y+sdnPP6YpI9lqgY/xCN5SuaHaHYOAAAAIOvYBSQDahIxWiUAAAAAyDoCXgbUFsfU1JPyuwwAAAAAiwwBLwNqkzE19gwrWzuUAgAAAIBEwMuI2mRMAyPj6kuN+10KAAAAgEWEgJcB0ztpsg4PAAAAQBYR8DKgttgLeOykCQAAACCbCHgZUJOMSqIXHgAAAIDsIuBlQFk8onBegBk8AAAAAFlFwMuAQMBUk4jqBAEPAAAAQBYR8DLE64VHwAMAAACQPQS8DKlJxNhFEwAAAEBWEfAypLY4prb+EY2MT/hdCgAAAIBFgoCXIVO98Fp7R3yuBAAAAMBiQcDLkLp0wDvRM+RzJQAAAAAWCwJehkzN4DX1pHyuBAAAAMBiQcDLkOqpZudstAIAAAAgSwh4GRLJC6q8MEKrBAAAAABZQ8DLoNpkTI0EPAAAAABZQsDLoNokzc4BAAAAZA8BL4Nqi70ZPOec36UAAAAAWAQIeBlUk4hqZHxSnYOjfpcCAAAAYBEg4GXQVKsEdtIEAAAAkA0EvAyqLZ7qhUfAAwAAAJB5BLwMqp2awSPgAQAAAMgCAl4GJWIhxcNBAh4AAACArCDgZZCZqYZWCQAAAACyhICXYVOtEgAAAAAg0wh4GebN4KX8LgMAAADAIkDAy7DaZExdg6MaGh33uxQAAAAAOY6Al2FTO2kyiwcAAAAg0wh4GTbVC491eAAAAAAyjYCXYTVJmp0DAAAAyA4CXoZVFkYUDJgauwl4AAAAADKLgJdhecGAqoqiOtE95HcpAAAAAHIcAS8L1tYUaevhLjnn/C4FAAAAQA4j4GXBHWur1Nyb0q7GPr9LAQAAAJDDCHhZcOvqCgVMemxPi9+lAAAAAMhhBLwsKImHdU1DiR7f0+p3KQAAAAByGAEvS25fU6l9Lf061slmKwAAAAAyg4CXJXesqZLEZZoAAAAAMoeAlyVLSvO1uqpQj3GZJgAAAIAMIeBl0R1rKrXtSJe6Bkf9LgUAAABADiLgZdHta6o06aTNe5nFAwAAADD3CHhZdFltkaoTUXbTBAAAAJARBLwsMjPdvqZST+1v1/DohN/lAAAAAMgxGQt4ZhY1s+fN7BUz221mn5jlnIiZfc/MDpjZVjNryFQ988Uda6qUGpvUMwc6/C4FAAAAQI7J5AzeiKRbnXNXSFov6U4zu/60c+6T1O2cWynpbyR9JoP1zAvXLS9RYTRPj+2mXQIAAACAuZWxgOc8A+mnofTNnXba3ZK+mX78kKQ3m5llqqb5IBQM6NbVFdq8r00Tk6f/zwEAAAAAFy6ja/DMLGhmL0tqk/S4c27raafUSjouSc65cUm9kkozWdN8cPuaSnUNjmr70W6/SwEAAACQQ8y5zM8imVlS0r9J+qBzbteM13dJutM5dyL9/KCk65xzHae9/35J90tSZWXl1Q8++GDGaz5fAwMDKigoOKdzh8edPrh5SLctzdO7VkcyXBlyyfmMM+BCMc6QaYwxZAPjDNng1zjbtGnTdufchtmO5WWjAOdcj5k9KelOSbtmHGqUVC/phJnlSUpI6pzl/V+T9DVJ2rBhg9u4cWPGaz5fW7Zs0fnUddOx57W3c1BvetOblONXpWIOne84Ay4E4wyZxhhDNjDOkA3zcZxlchfN8vTMncwsJul2SftOO+2Hkn47/fgdkp5w2ZhSnAfuWFupo51D2t828MYnAwAAAMA5yOQavGpJT5rZDkkvyFuD97CZfdLM3po+5wFJpWZ2QNKHJf1pBuuZV277hUpJYjdNAAAAAHMmY5doOud2SLpyltc/PuNxStI9maphPqssimp9fVKP72nVB25d5Xc5AAAAAHJARnfRxOu7Y22lXjnRq5belN+lAAAAAMgBBDwf3bHGu0zz8b2tPlcCAAAAIBcQ8Hy0orxAy8virMMDAAAAMCcIeD4yM92+plLPHepUX2rM73IAAAAALHAEPJ/dsbZSYxNOj+/mMk0AAAAAF4eA57Mr64u1vDyubz57RIukBSAAAACADCHg+SwQML3vpmXacaJX2452+10OAAAAgAWMgDcP/PpVtUrEQvr6M4f9LgUAAADAAkbAmwfyw3n6zeuW6NHdLTreNeR3OQAAAAAWKALePPGeG5YqYKZv/PyI36UAAAAAWKAIePNEdSKmt6yr1vdeOK5+WiYAAAAAuAAEvHnkv9+8TAMj4/r+thN+lwIAAABgASLgzSPr65O6emmxvvHzI5qYpGUCAAAAgPNDwJtn7rt5mY51Demne2l8DgAAAOD8EPDmmTvWVKo2GdMDtEwAAAAAcJ4IePNMXjCg997YoOcPd2lXY6/f5QAAAABYQAh489A7r61XPByk8TkAAACA80LAm4eKoiHds6FeP9rRpLa+lN/lAAAAAFggCHjz1HtvbND4pNO3nzvqdykAAAAAFggC3jzVUBbXm1dX6jtbjyk1NuF3OQAAAAAWAALePHbfzcvUNTiqf3+p0e9SAAAAACwABLx57PrlJVpTXaQHnjlM43MAAAAAb4iAN4+ZmX5/4wrtbxvQPzx9yO9yAAAAAMxzBLx57q7Lq3Xn2ip9/rFX6YsHAAAA4HUR8OY5M9On375OJfGwPvTgSxoeZcMVAAAAALMj4C0AxfGwPnfPFTrYPqhP/+dev8sBAAAAME8R8BaIW1aV676bl+lbzx7Vk/va/C4HAAAAwDxEwFtA/uSXLtXqqkL9yUOvqGNgxO9yAAAAAMwzBLwFJBoK6ovvWq++1Lg++tAOOUfrBAAAAAAnEfAWmNVVRfronau1eV+bvrP1mN/lAAAAAJhHCHgL0PtubNAtq8r0Vz/eowNtA36XAwAAAGCeIOAtQIGA6XP3XKFYKKg/+t5LGh2f9LskAAAAAPPAOQU8M/uQmRWZ5wEze9HM7sh0cTi7yqKoPv32ddrV2KfPPLKP9XgAAAAAznkG77875/ok3SGpWNJvSfrrjFWFc3LnZdV6zw1L9cAzh/XFn+73uxwAAAAAPss7x/Msff8WSd92zu02M3u9NyA7/tevrtXw6IS+tHm/zKQ/uu0Sv0sCAAAA4JNzDXjbzewxScskfczMCiWx8GseCARMn/n1y+UkffGn+xUw0x++eZXfZQEAAADwwbkGvPskrZd0yDk3ZGYlkt6XubJwPqZC3qRz+sLjr8kkfZCQBwAAACw65xrwbpD0snNu0Mz+m6SrJH0pc2XhfAUDps++4wrJSZ9//DUFAqY/2LTS77IAAAAAZNG5brLyFUlDZnaFpI9IOijpWxmrChckGDB99p4r9Lb1Nfrso6/q77cc8LskAAAAAFl0rjN44845Z2Z3S/qyc+4BM7svk4XhwgQDps/fu15O0v/7yKsymX5/4wq/ywIAAACQBeca8PrN7GPy2iPcYmYBSaHMlYWLEQyYPn/PFXJO+swj+9SfGtNH7rhUwQAbnwIAAAC57Fwv0XynpBF5/fBaJNVJ+mzGqsJFywsG9IV7r9BvXLtEf7/loO775gvqHR7zuywAAAAAGXROAS8d6r4jKWFmd0lKOedYgzfP5QUD+vTb1+lTv3aZfnagQ2/7u59pf2u/32UBAAAAyJBzCnhmdq+k5yXdI+leSVvN7B2ZLAxz593XLdU//8716k+N621/9zM9urvF75IAAAAAZMC5XqL5Z5Kucc79tnPuPZKulfQXmSsLc+2ahhL96IM3aWVloX7329v1hcdf0+Sk87ssAAAAAHPoXANewDnXNuN55xu918zqzexJM9tjZrvN7EOznLPRzHrN7OX07ePnUTvOU3Uipu/df73ecXWd/nbzft3/7W3qS7EuDwAAAMgV57qL5iNm9qik76afv1PST97gPeOSPuKce9HMCiVtN7PHnXN7TjvvaefcXedeMi5GNBTUZ99xudbVJvTJh/fobV/+mf7mnet1RX3S79IAAAAAXKRz3WTlTyR9TdLl6dvXnHMffYP3NDvnXkw/7pe0V1LtxZWLuWBm+u0bG/Sd91+nodEJ/drf/0yfeWSfUmMTfpcGAAAA4CKc6yWacs79q3Puw+nbv53PLzGzBklXSto6y+EbzOwVM/tPM1t7Pj8XF+f65aV67MO/qHuurtdXthzUXf/7Gb10rNvvsgAAAABcIHPu7BttmFm/pNlOMEnOOVf0hr/ArEDSf0n6lHPuB6cdK5I06ZwbMLO3SPqSc27VLD/jfkn3S1JlZeXVDz744Bv92qwbGBhQQUGB32VcsJ3t4/qn3aPqTjnduSykX1sZUjhIY/T5ZqGPMywMjDNkGmMM2cA4Qzb4Nc42bdq03Tm3YbZjrxvwLpaZhSQ9LOlR59wXzuH8I5I2OOc6znbOhg0b3LZt2+auyDmyZcsWbdy40e8yLkp/akz/z0/26bvPH9Py8rg++44rdPXSYr/Lwgy5MM4w/zHOkGmMMWQD4wzZ4Nc4M7OzBrxzvkTzAn6pSXpA0t6zhTszq0qfJzO7Nl1PZ6ZqwusrjIb06bev07fvu1YjY5N6x1d/rk/+aI8GRsb9Lg0AAADAOchYwJN0k6TfknTrjDYIbzGz3zOz30uf8w5Ju8zsFUl/K+ldLpNTijgnt6wq1yN/dIt+89ol+vrPDuvNn9+ih3c0if9rAAAAgPntXNsknDfn3DPy1uq93jlflvTlTNWAC1cYDelTv7ZOv351nf7i33fpA//8kh5ceVyfuHutVpRzPTsAAAAwH2VyBg854KolxfrhB27WJ966Vq+c6NGdX3xKn3v0VQ2P0lIBAAAAmG8IeHhDwYDXN2/zR96kuy6v0ZefPKDbvvBf+umeVr9LAwAAADADAQ/nrKIwqr9553p993euV344qPd/a5t+8x+e0/OHu/wuDQAAAIAIeLgAN6wo1U8+dIv+4q41eq11QPf+n2cJegAAAMA8QMDDBQkFA7rv5mV6+n9s0p//yi8Q9AAAAIB5gICHixILB/X+W5bPGvS2HqKlIQAAAJBNBDzMidmC3ju/9pze9nc/08M7mjQ+Mel3iQAAAEDOy1gfPCxOU0Hv3dct1fe3H9fXnzmsD/zzS6pNxvS+mxp07zX1KoqG/C4TAAAAyEnM4CEjYuGg3nNDgzZ/ZKP+4T0bVFcc01/9eK9u/PQT+uSP9uh415DfJQIAAAA5hxk8ZFQwYLp9TaVuX1OpnSd69cAzh/StZ4/oGz8/rNvXVOreDfV60yXlygvybw0AAADAxSLgIWvW1SX0xXddqY/+8mp98+dH9f1tx/Xo7laVF0b09itrdc+GOq2sKPS7TAAAAGDBIuAh66oTMf3pL6/Wh2+/RE++2qbvbzuhf3zmsP7PU4e0vj6pezbU6VevqGGtHgAAAHCeCHjwTTgvoF9aW6VfWlul9v4R/ftLjfr+9uP6s3/bpU/+aI9uW1OpX1lXrU2XVigWDvpdLgAAADDvEfAwL5QXRvQ7v7hc779lmXY29uqh7Sf0k53N+vGOZsVCQb35Fyr0K+uqtZGwBwAAAJwVAQ/zipnp8rqkLq9L6i9/da22Hu7Uj3c065FdLXp4R7Pyw0HdurpCd13uhb1oiLAHAAAATCHgYd4KBkw3rijTjSvK9Im3rtXzh7v08M4zwx4zewAAAICHgIcFIS8Y0I0ry3TjyjJ98q1rtfVwl368s1mPpsNeLBTUrenLOFmzBwAAgMWKgIcFJy8Y0E0ry3RTOuw9PxX2drdMr9n7xUvKdMuqct2yqkxLS+N+lwwAAABkBQEPC9opM3t3X6athzv1k53NemJvmx7d3SpJqi+J6eaVZbp5ZbluXFGq4njY56oBAACAzCDgIWfMXLPn7nY63DGoZw506On9HXr4lWZ99/njMpMuq0lo06XlumNtldbWFMnM/C4dAAAAmBMEPOQkM9Py8gItLy/Qe25o0PjEpF450atn9nfomQPt+vKTB/S3TxxQTSKq29dU6o61Vbp2WYlCwYDfpQMAAAAXjICHRSEvGNDVS4t19dJifei2VeoaHNXmva16bE+rvrftuL757FEVRfN06+oK3b6mSjevKlMiFvK7bAAAAOC8EPCwKJXEw7pnQ73u2VCv4dEJPb2/XY/tadXmva3695ebFDDpivqkbllZpptXlevKJUlm9wAAADDvEfCw6MXCQd2xtkp3rK3S+MSkXjzWo2f2t+up/R3Tl3IWRPJ0/fISb7OWVWVaUV7A2j0AAADMOwQ8YIa8YEDXLivRtctK9OE7LlXv0JiePdShp/Z36Jn9Hfrp3jZJUllBRNctL9H1y0p0/fJSrawg8AEAAMB/BDzgdSTyQ7rzsmrdeVm1JOlY55B+drBDWw916rlDXfrxjmZJUmk8rOuWl+i6ZaW6bnmJLqkoVCBA4AMAAEB2EfCA87CkNF9LSpfoN65dIuecjnUNaeuhLj13uFNbD3XpJztbJEmJWEjXNBTr2mUluqahRJfVJljDBwAAgIwj4AEXyMy0tDSupaVx3XtNvSTpeNeQnj/cpecPd+mFI13Tl3TGQkFdtTSpaxpKtL4+qcvrkiqh4ToAAADmGAEPmEP1JfmqL8nXr19dJ0lq609p25FuPX+4S1sPd+lLm/fLOe/cuuKYLq9LaF1tUpfXJXRZbYLWDAAAALgoBDwggyoKo3rLumq9ZZ23hq8vNabdjX3acaJHOxp7tfNE7/RlnZK0rCyuK+uTunJJUlcuKdbqqkLlcWknAAAAzhEBD8iiomhIN6wo1Q0rSqdf6xka1c7GXu040auXj/foqf0d+sFLjZK8Szsvr0voqqXFumpJsYZHnF+lAwAAYAEg4AE+S+aHdcuqct2yqlyS5JzTie5hvXisWy8d69FLx7r1D08d0vikF+4+89ITWr8kqfV1SV1Rn9S62oRi4aCfHwEAAADzBAEPmGfMbHot393rayVJqbEJ7Wzs1UNPbtdAJKmXj/VMt2gIBkyXVBZqfX1SV9YnddXSpJaXFdCmAQAAYBEi4AELQDQU1DUNJRpcFtLGjVdJktr7R/TK8R69cqJHLx/v0cM7mvTd549JkgqjeV7gW1Ksq5Yktb4+qWQ+u3YCAADkOgIesECVF0Z025pK3bamUpI0Oel0qGPwlEs7v/zEfqWv7NTysrguq01oXa23Y+fa2iIVRdm1EwAAIJcQ8IAcEQiYVlYUaGVFge7d4PXlGxgZ144TPXrpmDfL98KRLv3wlabp9zSU5uuydOC7vDahtbRqAAAAWNAIeEAOK4jk6cYVZbpxRdn0ax0DI9rV2KvdTX3amd658+H0ej7Ja9WwrjaR7tHnhb6CCF8VAAAACwH/1QYsMmUFEW28tEIbL62Yfq17cFS7mrxWDTtP9Gr70e7pmT4z7/LOhtK4KhNRVRVFVTXzPhFVYSRPZmzqAgAA4DcCHgAVx09t1SB5M307083Ydzb26kT3sF463qOuwdEz3l8UzdM1DSW6YUWprl9eqjXVReziCQAA4AMCHoBZlRVEtOnSCm2aMdMneS0b2vpG1NKXUnPvsFr7UjrcMajnDnVp8742SVIyP6TrlpXoxhVlumFFqVZVFDDDBwAAkAUEPADnJRoKaklpvpaU5p9xrLl3WM8e7NSzBzv184OdenR3qyRvhm91VZFWVxfq0qpCra4q1CWVhSpkF08AAIA5RcADMGeqEzG9/ao6vf2qOknS8a4hPXuwUy+f6NGrLf36wYuNGhgZnz6/rjg2HfYuqSzUqsoCrSgvUDQU9OsjAAAALGgEPAAZU1+Sr/qSfN17jde2wTmnE93D2tfSr1db+rSvpV/7Wvr15Kvtmkg37AuY1FAa16rKgnToK9SllYVaXh5XKBjw8+MAAADMewQ8AFljZtOh7/Z0g3ZJGh2f1OGOQb3W2q/9rf16rXVAr7X16/E9rdON2kNB04ryAl1adfIyz0urilSTiLK+DwAAII2AB8B34bzAdHCbKTU2oUPtg3q11Zvte62lXy8c7tJ/vHyyWXtBJE/Ly+NaUV6g5WVxrago0PJyr60Dl3oCAIDFJmMBz8zqJX1LUqUkJ+lrzrkvnXaOSfqSpLdIGpL0Xufci5mqCcDCEg0FtaamSGtqik55vXd4TK+1epd3Hmjt16GOQW091Kl/e6lx+hwzb43fivICrSwv0MqKAq2qLNDK8kIl8tncBQAA5KZMzuCNS/qIc+5FMyuUtN3MHnfO7Zlxzi9LWpW+XSfpK+l7ADirRCykaxpKdE1DySmvD42O61D7oA51DOpQ+4AOtg/qQNuAnj3YqZHxyenzygoiWlkR18qKAi0r82b+lpXFVVccUx7r/AAAwAKWsYDnnGuW1Jx+3G9meyXVSpoZ8O6W9C3nnJP0nJklzaw6/V4AOC/54TxdVpvQZbWJU16fmHRq7B7WgfZ+HWgbmL798OUm9aVO7uqZFzAtKcnXsnTgW1bu3a8oL1BFYYS1fgAAYN7Lyho8M2uQdKWkracdqpV0fMbzE+nXCHgA5kwwYNO9+25dfXJzF+ecuofGdLhjQIfaB3W44+TtZwc7lBo7OesXDwe1rDyu5WXeGr/l5QWqK46psiiq8oKIwnnM/AEAAP+ZN3mWwV9gViDpvyR9yjn3g9OOPSzpr51zz6Sfb5b0UefcttPOu1/S/ZJUWVl59YMPPpjRmi/EwMCACgoK/C4DOY5xlj2Tzqk75dQ86NQyOJm+ObUMTapz2On0b87CkJSMBpSMmJIRU3HUVFcY0LKigMpitqBm/xhnyDTGGLKBcYZs8GucbdRIEG4AABoKSURBVNq0abtzbsNsxzI6g2dmIUn/Kuk7p4e7tEZJ9TOe16VfO4Vz7muSviZJGzZscBs3bpz7Yi/Sli1bNB/rQm5hnM0PqbEJHekcVHNPSq19KbX2jai1P6W29ONX+1LqaBqZbvGQiIW0Ln3p6Lr0rb4kNm9DH+MMmcYYQzYwzpAN83GcZXIXTZP0gKS9zrkvnOW0H0r6gJk9KG9zlV7W3wGY76KhoFZXFWl1VdFZzxkZn9CrLf3a2dirXY292tnYqweeOaSxCS/1FUbztLy8QCumWjuUeZd9Li3Np70DAAC4YJmcwbtJ0m9J2mlmL6df+5+SlkiSc+6rkn4ir0XCAXltEt6XwXoAIGsieUFdXpfU5XXJ6ddGxif0WsuAdjb2am9znw51DOjnBzv1gxntHQIm1RXnq6EsriUlMS0tiau+JF9LSrw1hAUR2pcCAICzy+Qums9Iet3rj9K7Z/5BpmoAgPkkkhfUurqE1tWdusvn4Mi4DncM6mC6tcPB9gEd6xzSy8e6T9nlU5JK42HVl+SrNhlTVSKq6kRU1YmTjysKI7R6AABgEeOfggHAZ/HI7O0dJKl3aEzHuoZOuR3vGtLelj49sa9Nw2MTp5wfMKmqKOpd/lnuXf65oty7VRbR6gEAgFxHwAOAeSyRH9K6/DNn/SSvzUPf8Lia+4bV3JNSc29Kzb3DOtE9rEPtA/rXFxs1MHJyBjAeDmp5eYGWlcW1tDRfS0vT9yX5KqfPHwAAOYGABwALlJkpkR9SIj8064Yvzjm194/owNSln20DOtg+oJeOd+vhHU3Tu3xKUiwU1NJSb61fYGhExyNHVF/ihcDaZIw+fwAALBAEPADIUWamiqKoKoqiunFF2SnHxiYm1dg9rCOdgzrWNaQjHUM61jWoQx2DOtoxrkeO7J7xc6SaREz1JTEtKfE2gFlWGtfS0rgayvKVH+ZPCQAA8wV/lQFgEQoFA2ooi6uhLH7GsSeefFJrr77BW/PXeXLd37GuIT2xr10dAydOOb+yKKKG0rgaSuNaUpqvqqKoqhLpW1FUcXb+BAAga/irCwA4RcBMlUVRVRZFdU1DyRnHB0bGdaRjUEc6B9P3QzrSMajN+1rVMTB6xvmF0TxVJ7yfV5uMqa44ptrimGqT+aorjqmyKKpggPV/AADMBQIeAOC8FLzOrp/DoxNq7fM2fGnpG1ZL74haeofTz1Pa29x3RgjMC5iqElHVFXt9/5aW5Xv3pflaWpqvwmgoWx8NAIAFj4AHAJgzsXDwrJd+ThkenVBjz7B36x7Wie4hNfZ4u39u3temjoGRU84vjYenN4CpLY6pJund6tL3XAIKAMBJ/FUEAGRVLBzUyooCrawomPX4wMi4jnYO6ljnkI50Dulo56COdg7phSPdenhHs8Znbv8pKZkfUk3Cu/SzviRf9VP3Jd4loGwCAwBYTPirBwCYVwoieVpbk9DamjMvAZ2YdGrrT6mxe3h6FrApPRN4uGNQT+1vV2ps8pT3lBWEVVucr7qkt/avJhFVbXG+apJR1SXzVRTLowcgACBnEPAAAAtGMGCqTsRUnYhpwyzHnXPqGBjV8W5v588T3cPT93ub+/TTva0aGT81AMbDQdUWey0gvBlA73LQJaXe41g4mJ0PBwDAHCDgAQByhpmpvDCi8sKIrlpSfMZx55w6B0fV2J2e+Uvfjnd5awF/frBTQ6MTp7ynrCCiJSWxU8JfXbonYHUixg6gAIB5hYAHAFg0zExlBRGVFUR0RX3yjOPOOXUNjno9ANMzf0c7B3W8a1jbj3prACdmrAHMC5hqkl4T+Lp024e6kpjqir3HFYW0gAAAZBcBDwCANDNTaUFEpQURXTnLDODYxKSae1I63n1qA/jGnmE98Wqb2vtP3QE0FLTphu8VRVFVFkZVlYhM9xmsLIqqOhFVNMRloACAuUHAAwDgHIWCAS0p9dbn3TTL8dTYxHTLhxPd3gxgY/ew2vpT2tPUpyd62zQ8NnHG+2ZuBDPVCL4u3Qy+voSdQAEA546/GAAAzJFoKKgV5QVaUT57CwjnnAZGxtXaN6LWvpRaelNq7h2eDoV7m/v0+N5WjY6fuRNofYm3/m9qHeBUG4iqRFShYCAbHw8AsAAQ8AAAyBIzU2E0pMJo6Kx9ACcnnToGR9KzgN4uoFOXgm4/2q0fvdKkma0AzaTygoiqE1FVJaLpXUajqk7GVFU0dXlohMtAAWCRIOABADCPBAKmisKoKgqjs+4EOrUO8FjXkI53D6m5N6WW3mE196Z0sH1Qz+zv0ODomZeBFueHVFkUnV4TWFkUVU0yqtpkvmqLY6wFBIAcQcADAGABmbkO8Gz6U2Pp4JdSS19KrVP3fd79rsY+dQ6OyLlT31dWEPHW/yVjqkl6IbOiKDLjPqKCCI3hAWA+I+ABAJBjpi4DvaSy8KznjI5PqrUvpRMzegJO3e9t6dPmfa1KjU2e8b5YKKjKIm8n0NqktyFMTdK71SajqkmyKQwA+IlvYAAAFqFwXsBr3l4y+0ygc079I+Nq6xtRW19Kbf0jautPqa1vRK39I2rtTWnr4S61vJI6pTeg5F0OOrUpzNLSfC0tiWtJqfe4sjCajY8HAIsWAQ8AAJzBzFQUDanodTaEkaTxiUm19o+oKT0DeKLbmwU83jWkHSd69Z+7Wk4JgOG8gEojTisPbk1vDBNTTXpTmOqE1xewMBrKxkcEgJxEwAMAABcsLxjwLtVMxmY9Pj4xqaaelI52Depop7cb6IuvHlVfalyvtrSrfeDMtYCFkTxVJ70dQWuSJ3cGrU3GpncHjYXZEAYAZkPAAwAAGZM3Y1OYW1Z5r23Jb9XGjV6r+NHxSbX1p9Tcm1JTz7Ba0vdN6R6Buxp71Tk4esbPLYrmqSrh7QZald4ddOrxVDgszg+xIQyARYeABwAAfBPOC6iuOF91xWffFTQ1NuEFv95hNfd4O4G2zNgZ9LXWfrX3j+i0pYCK5AXO7A+YDoLVCa9JfGk8rECAEAggdxDwAADAvBYNBdVQFldDWfys54xPTKpjYFTNvcNq7UupKR0Ep2YFnz/cpda+lMZPS4GhoNd3sGoqCBbNeJxeI1hRGFEoGMj0xwSAOUHAAwAAC15eMDAdzM5mYtKpc2BELX3eJaGt6fuW9G1PU5827z2zPYSZ1yNwqkF8VWLm43Tj+ERUhfQIBDAPEPAAAMCiEAyYKoqiqiiK6vK62c9xzqlveFzNfcNeCOw9GQKb+1I60T2kbUe71DM0dsZ74+HgdE/AmmRMdcXeJjE1Ce95ZVFU4TxmAgFkFgEPAAAgzcyUyA8pkR/S6qqis56XGptQa3ot4FRfwKk1go09Z98cpjQeVmVRdLpZfMXU48Joull8TEUxZgIBXDgCHgAAwHmKhoJaWhrX0tKzrwscHp1QU6/XH7Cxezi9KYzXOL61P6VdTX3qmKVNREEkTzVJry1ETTKm2mJvg5iSeEQl+WEVx0MqiYeVH+Y/4wCciW8GAACADIiFg1pRXqAV5WdvFD82MamOgRHvEtDelBrTjeIb043jXz7eo+5ZLgeVpGgokA58YZUXRqbbRZy+U2hRlBlBYDEh4AEAAPgkFAykWzjEdOVZzhkcGVdrX0rdQ6PqHBhV99CougbHpp93DY6ofWBEuxq9GcHT5YeDqiuOaUlJvpaUxLWkJOb1JiyJq644pmiIpvFALiHgAQAAzGPxSJ6Wv84s4ExTjeOnZgSnWkYc7x7S8a4h/fxgp4ZGJ055T2VRRFWJ2CktIqqKTr0nBAILBwEPAAAgR7xR43jnnDoGRnWsywt8RzuHdLx7SK19KR1sH9DPDnSof2T8jPeVxMPTjeKrEzFVp3cHnW4TURRVLEwIBOYDAh4AAMAiYWYqL4yovDCiq5cWz3rOwMj4dG/A6cbxvSk19wzrRPewXjjSrd7hM9cFFkbzTu4QWuj1BqwsjEy3jahNxpTMD7EeEMgwAh4AAACmFUTytLKiQCsrzn5Z6ODIuJqnA+CIWvtS3u6gfSNq7U9p6+EutfWnNDZx6hah0VBgOuzVpGcCZ7aNqCyKqiQ/rECAEAhcKAIeAAAAzkv8HELg5KRT5+ComnuH1dSTUlN6Z9Cm3mE19qS0t7lt1k1h8gKmisKIKoqiyg8HlRcMKC9gCgZMoaApGPCeh4Km/HCeYuGg4uGg8sN5yg8HlR/JUzwc1NHeCV03OsGlo1h0CHgAAACYc4HAyctBL6+b/ZzR8Um1D5w6A+j1C0yprW9EqbEJDY1OaHxyUuMTThOT3m1sclJj407DYxMaHBnX+KSb9ef/1XOPaHl5gdbWFGlNdZHWpO9LCyIZ/OSAvwh4AAAA8EU4L6Da9CWbF2N0fFLDoxMaHB3X0Oi4hkYn9Ngz2xQoXaI9Tb164XCX/uPlpunzK4siuqSyUCsrCrSqonB6NrIkHr7YjwT4joAHAACABS2cF1A4L6BEfmj6ta6qPG3ceMn08+7BUe1t7tPupj7tae7Ta639+u7zx5Qam5w+pyQe1sryAq2oiKs2GZveMdTrVUi7CCwMBDwAAADkvOJ4WDeuLNONK8umX5ucdGrsGdaB9gEdbBvQgfTt0d2t6hocPeNnTLWLqCyKqqwgrNKCiMoKIt7jeESlBWGVFURUEg8ryEYx8AkBDwAAAItSIGCqL8lXfUm+Nl1accqx4dEJtfR57SGaelNq6Z269267m3rVOTA66/q/YMBUXhCZ3h20KhGd3iW0qiiqumKvdUQ4L5Ctj4pFhIAHAAAAnCYWDmpZWVzLyuJnPcc5p77hcXUMjqijf0Sdg6PqGBhRW7p1REtfSkc6B/XcoU71pU5tIB8wqToRU31JTEtK8rUkHTTrivNVk4yqojDKLCAuCAEPAAAAuABmpkR+SIn8kFaUn71lhOTNCLb2pdTcm9KJ7iEd7xrSsa4hHe8e1pOvtqu9/9SWEcGAqaooqupEVNXJmGoS3mMax+ONEPAAAACADIuFg2ooi6uhLC6p9Izjw6MTXvDrHlJTj9dEvrknpabeYb1yvEeP7kppdGLylPfkh4MzAp+3GczU5aBV6QbyiRghcLHJWMAzs69LuktSm3PuslmOb5T0H5IOp1/6gXPuk5mqBwAAAJivYuGgVlUWalVl4azHZzaOb+weVmPPjAbyvcPa09SrjoEzN4aJ5AXS6/8i08GvKpG+FZ1cG8h6wNyRyRm8b0j6sqRvvc45Tzvn7spgDQAAAMCCd2rj+OSs56TGJtTef3L9X2vfiNqmH6e0u6lPm/e2aXhs4oz3lhWEVZWIqibhzQievBzUu2dN4MKRsYDnnHvKzBoy9fMBAAAAnBQNBad3BT2bqY1hWvq8y0Bb+1Jq6R1RS9+wmnu9TWF+frBTAyOnbgoTDJhK414biLJCrzVE+VSbiMKwKgqjqi/OV3UyqlCQ2UA/+b0G7wYze0VSk6Q/ds7t9rkeAAAAIGfN3Bjm0qrZLweVpL7U2PQawKYebz1ge/+IOga824HWfnUMjJ6xLjAYMNUko6fsDFpfnK+aZGy6d2A8HGRdYAaZc2f27pizH+7N4D18ljV4RZImnXMDZvYWSV9yzq06y8+5X9L9klRZWXn1gw8+mLGaL9TAwIAKCl5/9yTgYjHOkA2MM2QaYwzZwDjLPOechsalvhGnnhGn9uFJtQ+det935rJAhQJSUdhUFDYVRrz7RNiUiJiSEe9+6nE0b34HQb/G2aZNm7Y75zbMdsy3gDfLuUckbXDOdbzeeRs2bHDbtm2bk/rm0pYtW7Rx40a/y0COY5whGxhnyDTGGLKBcTY/DI6M63j3kFp6U+ocGFXn4Ig6B0bVPjAy/byj3+sfOFvT+Hg4qMqiqOpK8rU0PSu4pDR/eoYwHvH3gkS/xpmZnTXg+fa/iJlVSWp1zjkzu1ZSQFKnX/UAAAAAmFvxSJ5WVxVpdVXR6543OenUMzym9v4RtfWn1NY3ovYZTeOPdw/pleM96h0eO+V9ZQUR1RbHVFEYSd+iqig69XFpPKy8RbQuMJNtEr4raaOkMjM7IekvJYUkyTn3VUnvkPT7ZjYuaVjSu1wmpxMBAAAAzEuBgKkkHlZJPPy6awN7h8Z0rGtIR7sGdaxrSMc6h9TYM6zjXUPafrRbXYNnXhNqJhXnh1VWkN4kpsDbjXTqfklJvpaW5quiMJITawMzuYvmb7zB8S/La6MAAAAAAG8okR/SuvyE1tUlZj0+Oj6ZnvlLqa1/RG39I+pIbw4ztUnMy8d71DEwoqHRU9tFxELB6bDn3eJqKI3r5lVl2fhoc8bvXTQBAAAAYE6E8wKqTcZUm4y94bmDI+Nq6x/xZgQ7B3WkY0jHugZ1qGNQW15r1+j4pMoLI3rhz27LQuVzh4AHAAAAYNGJR/K0LJKnZWVxSeWnHJucdGrpS816yed8R8ADAAAAgBkCAVNNMqaac5gJnG8Wz3YyAAAAAJDjCHgAAAAAkCMIeAAAAACQIwh4AAAAAJAjCHgAAAAAkCMIeAAAAACQIwh4AAAAAJAjCHgAAAAAkCMIeAAAAACQIwh4AAAAAJAjzDnndw3nxczaJR31u45ZlEnq8LsI5DzGGbKBcYZMY4whGxhnyAa/xtlS51z5bAcWXMCbr8xsm3Nug991ILcxzpANjDNkGmMM2cA4QzbMx3HGJZoAAAAAkCMIeAAAAACQIwh4c+drfheARYFxhmxgnCHTGGPIBsYZsmHejTPW4AEAAABAjmAGDwAAAAByBAFvDpjZnWb2qpkdMLM/9bseLHxmVm9mT5rZHjPbbWYfSr9eYmaPm9n+9H2x37Vi4TOzoJm9ZGYPp58vM7Ot6e+075lZ2O8asbCZWdLMHjKzfWa218xu4PsMc8nM/u/038tdZvZdM4vyXYa5YGZfN7M2M9s147VZv7/M87fpMbfDzK7yo2YC3kUys6Ckv5P0y5LWSPoNM1vjb1XIAeOSPuKcWyPpekl/kB5Xfypps3NulaTN6efAxfqQpL0znn9G0t8451ZK6pZ0ny9VIZd8SdIjzrnVkq6QN974PsOcMLNaSX8oaYNz7jJJQUnvEt9lmBvfkHTnaa+d7fvrlyWtSt/ul/SVLNV4CgLexbtW0gHn3CHn3KikByXd7XNNWOCcc83OuRfTj/vl/cdQrbyx9c30ad+U9DZ/KkSuMLM6Sb8i6R/Tz03SrZIeSp/COMNFMbOEpF+U9IAkOedGnXM94vsMcytPUszM8iTlS2oW32WYA865pyR1nfby2b6/7pb0Led5TlLSzKqzU+lJBLyLVyvp+IznJ9KvAXPCzBokXSlpq6RK51xz+lCLpEqfykLu+KKk/yFpMv28VFKPc248/ZzvNFysZZLaJf1T+lLgfzSzuPg+wxxxzjVK+pykY/KCXa+k7eK7DJlztu+veZELCHjAPGZmBZL+VdIfOef6Zh5z3ha4bIOLC2Zmd0lqc85t97sW5LQ8SVdJ+opz7kpJgzrtcky+z3Ax0uuf7pb3jwk1kuI685I6ICPm4/cXAe/iNUqqn/G8Lv0acFHMLCQv3H3HOfeD9MutU1P96fs2v+pDTrhJ0lvN7Ii8y8tvlbdWKpm+zEniOw0X74SkE865rennD8kLfHyfYa7cJumwc67dOTcm6Qfyvt/4LkOmnO37a17kAgLexXtB0qr0Tk1heYt6f+hzTVjg0uugHpC01zn3hRmHfijpt9OPf1vSf2S7NuQO59zHnHN1zrkGed9dTzjn3i3pSUnvSJ/GOMNFcc61SDpuZpemX3qzpD3i+wxz55ik680sP/33c2qM8V2GTDnb99cPJb0nvZvm9ZJ6Z1zKmTU0Op8DZvYWeetYgpK+7pz7lM8lYYEzs5slPS1pp06ujfqf8tbh/YukJZKOSrrXOXf6wl/gvJnZRkl/7Jy7y8yWy5vRK5H0kqT/5pwb8bM+LGxmtl7eRj5hSYckvU/ePzLzfYY5YWafkPROebtQvyTp/fLWPvFdhotiZt+VtFFSmaRWSX8p6d81y/dX+h8YvizvEuEhSe9zzm3Les0EPAAAAADIDVyiCQAAAAA5goAHAAAAADmCgAcAAAAAOYKABwAAAAA5goAHAAAAADmCgAcAWHTM7NNmtsnM3mZmH8vS7zxiZmXZ+F0AgMWLgAcAWIyuk/ScpDdJesrnWgAAmDMEPADAomFmnzWzHZKukfSsvGbIXzGzj5vZCjN7xMy2m9nTZrY6/Z5vmNlXzWybmb1mZnelX4+a2T+Z2U4ze8nMNqVfD5rZ58xsl5ntMLMPzijhg2b2Yvo9q7P88QEAi0Ce3wUAAJAtzrk/MbN/kfQeSR+WtMU5d5MkmdlmSb/nnNtvZtdJ+ntJt6bf2iDpWkkrJD1pZisl/YH3I926dFh7zMwukfS+9PnrnXPjZlYyo4QO59xVZvZ/SfpjeQETAIA5Q8ADACw2V0l6RdJqSXslycwKJN0o6ftmNnVeZMZ7/sU5Nylpv5kdSr/3Zkn/W5Kcc/vM7KikSyTdJumrzrnx9LGuGT/nB+n77ZLePvcfDQCw2BHwAACLgpmtl/QNSXWSOiTley/by/LW4vU459af5e3uDZ6fq5H0/YT4GwwAyADW4AEAFgXn3MvpAPeapDWSnpD0S8659c65XkmHzeweyUt9ZnbFjLffY2YBM1shabmkVyU9Lend6fMvkbQk/frjkn7XzPLSx2ZeogkAQEYR8AAAi4aZlUvqTl9uudo5t2fG4XdLus/MXpG0W9LdM44dk/S8pP+Ut04vJW+NXsDMdkr6nqT3OudGJP1j+vwd6Z/1m5n+XAAATDHnLvQqEwAAcp+ZfUPSw865h/yuBQCAN8IMHgAAAADkCGbwAAAAACBHMIMHAAAAADmCgAcAAAAAOYKABwAAAAA5goAHAAAAADmCgAcAAAAAOYKABwAAAAA54v8HvXs/PXPZokAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_loss(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The final loss is better, but not so significant, may be with tuned lr the difference will be large**"
      ],
      "metadata": {
        "id": "EhY-VU_GhcFT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp_ZQWH5YzEE"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "collapsed": true,
        "id": "chUuX5J9YzEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08e1bfe-0d75-45ab-eaa1-6790bfacb1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "temperature:  0.1\n",
            "если бы я мой\n",
            "во все девой последней того,\n",
            "как он мог онегин поэта,\n",
            "и в самом деревне с ним страна\n",
            "и темное старины простой\n",
            "и стал без молодой в долей.\n",
            "\n",
            "\n",
            "\n",
            "xxxii\n",
            "\n",
            "сей под ней и под венерный,\n",
            "в сем не встречает на свете,\n",
            "и нет на стала не своей.\n",
            "она в семерью веселья стройной\n",
            "старинуться возов дороги,\n",
            "и после наш онегина своей\n",
            "надель и вот просто она\n",
            "свои простой толку волненье,\n",
            "в постелет мой обедала стралось\n",
            "в сем не встречает на свете,\n",
            "и в сердцем полковые мечты,\n",
            "не знала он был поразленный,\n",
            "и \n",
            "####################################################################################################\n",
            "temperature:  0.2\n",
            "если бы я мел\n",
            "\n",
            "\n",
            "\n",
            "xxvii\n",
            "\n",
            "«муж татьяна полно, понять молодной\n",
            "в своей и соседа подруга\n",
            "старушка молодой послед,\n",
            "и страстей и в солнце тогда\n",
            "я был он простой то скука,\n",
            "к мой модных девицы своей души\n",
            "и вольное стали нежной.\n",
            "\n",
            "\n",
            "\n",
            "xiii\n",
            "\n",
            "и страшно гордость верно всех,\n",
            "не отрадитель с ним одна,\n",
            "и в сад нежной так уж сосед\n",
            "с первый слез и друг он всех долгой,\n",
            "и слезы ль\n",
            "####################################################################################################\n",
            "temperature:  0.5\n",
            "если бы я мел\n",
            "от конемин пока стройный\n",
            "в нем должен, не вам два страдах,\n",
            "воспомнил с рожда пора собой,\n",
            "востой дорогой возразнай,\n",
            "и слеза, мечтанья своей\n",
            "и нетернает татьяна:\n",
            "вдруг душа волненный весел,\n",
            "старен привычный полодой\n",
            "в постелет едва затов бесты,\n",
            "и таня в строгах поравленья,\n",
            "и волнец из ней и страстной\n",
            "старушки смерен буду два;\n",
            "он и страстей полукровенье,\n",
            "и в нем одевался онегин.\n",
            "\n",
            "\n",
            "\n",
            "xxiii\n",
            "\n",
            "ко гом по нему подева строй,\n",
            "свои пред семей петремена,\n",
            "в окну покорых лет и при\n",
            "####################################################################################################\n",
            "temperature:  1.0\n",
            "если бы я мог\n",
            "и чем же твоей девирого\n",
            "####################################################################################################\n",
            "temperature:  2.0\n",
            "если бы я м9»\n",
            "\n",
            "знай! что: всрею вь яг: гого, були?,;\n",
            "xl ину, ззовся,\n"
          ]
        }
      ],
      "source": [
        "# Text generation with different temperature values here\n",
        "temperatures = [0.1, 0.2, 0.5, 1.0, 2.0]\n",
        "for temperature in temperatures:\n",
        "    print('#'*100)\n",
        "    print('temperature: ', temperature)\n",
        "    print(generate_text(model, seed_phrase='если бы я м', max_length=500, temperature=temperature, is_lstm=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like temperatures < 0.5 provide better results, than >= 0.5. Apparently, this is because some letters have high prior probability. So, lower temperature decrease impact of prior probability**"
      ],
      "metadata": {
        "id": "C_WP5f3_jQGU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKEXTcbUYzEF"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7DM9kENYzEF"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "collapsed": true,
        "id": "SCgTNnk7YzEF"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = LSTM()\n",
        "model_loaded.load_state_dict(torch.load('model'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea80P75XkRzk",
        "outputId": "26b97183-804e-40c3-e195-d9475d35fffa"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model_loaded, seed_phrase='хочу отдохн', max_length=500, temperature=0.2, is_lstm=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfnt81bkmom",
        "outputId": "612a7b34-0460-40af-ca02-f411f87f3de7"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хочу отдохной\n",
            "он из волной сон возрастой\n",
            "в душа в семеньем молодой,\n",
            "и слезы ль\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2BokPKmYzEF"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}