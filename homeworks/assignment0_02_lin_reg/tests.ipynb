{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ec986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "111591bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1dim = np.arange(16).reshape(16, 1)\n",
    "x_4dim = np.arange(16 * 4).reshape(-1, 4)\n",
    "\n",
    "x_1dim_torch = torch.tensor(x_1dim, dtype=torch.float32, requires_grad=True)\n",
    "x_4dim_torch = torch.tensor(x_4dim, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e6a0e6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1]), torch.Size([16, 4]))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1dim_torch.shape, x_4dim_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1f8afc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1dim = np.arange(16)\n",
    "y_3dim = np.arange(16 * 3).reshape(16, 3)\n",
    "\n",
    "y_1dim_torch = torch.tensor(y_1dim, dtype=torch.float32)\n",
    "y_3dim_torch = torch.tensor(y_3dim, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "db268c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]), torch.Size([16, 3]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1dim_torch.shape, y_3dim_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1be9498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1_1_dim = np.array([1.3])\n",
    "w_4_1_dim = np.array([1.3, 1.6, 1.8, 2.0])\n",
    "w_1_3_dim = np.array([[1.3, 1.3, 1.3]])\n",
    "w_4_3_dim = np.vstack([w_4_1_dim, w_4_1_dim, w_4_1_dim]).T\n",
    "\n",
    "w_1_1_dim_torch = torch.tensor(w_1_1_dim, dtype=torch.float32, requires_grad=True)\n",
    "w_4_1_dim_torch = torch.tensor(w_4_1_dim, dtype=torch.float32, requires_grad=True)\n",
    "w_1_3_dim_torch = torch.tensor(w_1_3_dim, dtype=torch.float32, requires_grad=True)\n",
    "w_4_3_dim_torch = torch.tensor(w_4_3_dim, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c9adc7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), torch.Size([4]), torch.Size([1, 3]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_1_1_dim_torch.shape, w_4_1_dim_torch.shape, w_1_3_dim_torch.shape, w_4_3_dim_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fac8c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def mse(X, Y, w):\n",
    "    loss = nn.MSELoss()\n",
    "    output = loss(X @ w, Y)\n",
    "    output.backward()\n",
    "    dev = np.array(w.grad)\n",
    "    w.grad.data.zero_()\n",
    "    X.grad.data.zero_()\n",
    "    return dev, output.detach().numpy()\n",
    "\n",
    "def my_mse(X, Y, w):\n",
    "    loss = np.mean((X.dot(w) - Y)**2)\n",
    "    dev = 2 / Y.size * X.T @ (X.dot(w) - Y)\n",
    "    return dev, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2bf141dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_np = [\n",
    "    (x_1dim, y_1dim, w_1_1_dim),\n",
    "    (x_1dim, y_3dim, w_1_3_dim),\n",
    "    (x_4dim, y_1dim, w_4_1_dim),\n",
    "    (x_4dim, y_3dim, w_4_3_dim),\n",
    "]\n",
    "setup_torch = [\n",
    "    (x_1dim_torch, y_1dim_torch, w_1_1_dim_torch),\n",
    "    (x_1dim_torch, y_3dim_torch, w_1_3_dim_torch),\n",
    "    (x_4dim_torch, y_1dim_torch, w_4_1_dim_torch),\n",
    "    (x_4dim_torch, y_3dim_torch, w_4_3_dim_torch), \n",
    "    #16x4, 16x3, 4x3 (XW - y) ** 2 -> 16x3 sum() / 16*3\n",
    "    # 4x3: 2 * (XW - Y) * X; 16x3 16x4 -> 16x4.T * 16x3 -> 4x3 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "57d9ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for np_setup, torch_setup in zip(setup_np, setup_torch):\n",
    "    expected = mse(*torch_setup)\n",
    "    actual = my_mse(*np_setup)\n",
    "    assert np.allclose(expected[0], actual[0])\n",
    "    assert np.allclose(expected[1], actual[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "be5b8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(X, Y, w):\n",
    "    loss = nn.L1Loss()\n",
    "    output = loss(X @ w, Y)\n",
    "    output.backward()\n",
    "    dev = np.array(w.grad)\n",
    "    w.grad.data.zero_()\n",
    "    X.grad.data.zero_()\n",
    "    return dev, output.detach().numpy()\n",
    "\n",
    "def my_mae(X, Y, w):\n",
    "    loss = np.mean(np.abs(X.dot(w) - Y))\n",
    "    sign = np.sign(X.dot(w) - Y)\n",
    "    dev = X.T @ sign / Y.size\n",
    "    return dev, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4d4d8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for np_setup, torch_setup in zip(setup_np, setup_torch):\n",
    "    expected = mae(*torch_setup)\n",
    "    actual = my_mae(*np_setup)\n",
    "    assert np.allclose(expected[0], actual[0])\n",
    "    assert np.allclose(expected[1], actual[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8a9e5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_reg(w):\n",
    "    output = torch.sum(w ** 2)\n",
    "    output.backward()\n",
    "    dev = np.array(w.grad)\n",
    "    w.grad.data.zero_()\n",
    "    return dev\n",
    "\n",
    "def my_L2_reg(w):\n",
    "    return 2 * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "dd6a22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for np_setup, torch_setup in zip(setup_np, setup_torch):\n",
    "    expected = L2_reg(torch_setup[2])\n",
    "    actual = my_L2_reg(np_setup[2])\n",
    "    assert np.allclose(expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5918504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_reg(w):\n",
    "    output = torch.sum(torch.abs(w))\n",
    "    output.backward()\n",
    "    dev = np.array(w.grad)\n",
    "    w.grad.data.zero_()\n",
    "    return dev\n",
    "\n",
    "def my_L1_reg(w):\n",
    "    return np.sign(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2802c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for np_setup, torch_setup in zip(setup_np, setup_torch):\n",
    "    expected = L1_reg(torch_setup[2])\n",
    "    actual = my_L1_reg(np_setup[2])\n",
    "    assert np.allclose(expected, actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
